# -*- coding: utf-8 -*-
"""CISC642_PR3_pt2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BVVO-Y489VfWTU02PDaCcHMBzbgeBYzO
"""

import time
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
from torchvision import datasets, transforms

# Check if GPU is available
device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")

# Data transformations
data_transforms = transforms.Compose([
    transforms.Resize((32, 32)),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))
])

# Datasets
dataset_root = './data'
trainset = datasets.CIFAR100(dataset_root, train=True, transform=data_transforms, download=True)
testset = datasets.CIFAR100(dataset_root, train=False, transform=data_transforms, download=True)

# DataLoaders
batch_size = 32
trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=0)
testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=0)

# Define custom CNN
class CustomCNN(nn.Module):
    def __init__(self):
        super(CustomCNN, self).__init__()
        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)
        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)
        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)
        self.fc1 = nn.Linear(256 * 4 * 4, 512)
        self.fc2 = nn.Linear(512, 100)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.pool(self.relu(self.conv1(x)))
        x = self.pool(self.relu(self.conv2(x)))
        x = self.pool(self.relu(self.conv3(x)))
        x = x.view(-1, 256 * 4 * 4)
        x = self.relu(self.fc1(x))
        x = self.fc2(x)
        return x

model = CustomCNN().to(device)

# Loss function and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)

# Training loop with time and progress tracking
num_epochs = 30
best_loss = float('inf')

for epoch in range(num_epochs):
    print(f'Epoch {epoch+1}/{num_epochs}')
    start_time = time.time()
    running_loss = 0.0
    model.train()

    total_batches = len(trainloader)
    for i, (inputs, labels) in enumerate(trainloader):
        inputs = inputs.to(device)
        labels = labels.to(device)

        optimizer.zero_grad()

        outputs = model(inputs)
        loss = criterion(outputs, labels)

        loss.backward()
        optimizer.step()

        running_loss += loss.item()

        # Calculate and print progress percentage
        progress = (i + 1) / total_batches * 100
        print(f'\rProgress: {progress:.2f}% [{i+1}/{total_batches}]', end='')

    elapsed_time = time.time() - start_time
    print(f'\nEpoch [{epoch+1}/{num_epochs}], Loss: {running_loss / len(trainloader)}, Time: {elapsed_time:.2f}s')

    if running_loss < best_loss:
        best_loss = running_loss
        torch.save(model.state_dict(), 'custom_best_model.pth')

# Load the best model for evaluation
model.load_state_dict(torch.load('custom_best_model.pth'))
model.eval()

# Testing loop with time and progress tracking
correct = 0
total = 0
start_time = time.time()

total_batches = len(testloader)
with torch.no_grad():
    for i, (inputs, labels) in enumerate(testloader):
        inputs = inputs.to(device)
        labels = labels.to(device)

        outputs = model(inputs)
        _, preds = torch.max(outputs, 1)
        correct += (preds == labels).sum().item()
        total += labels.size(0)

        # Calculate and print progress percentage
        progress = (i + 1) / total_batches * 100
        print(f'\rTesting Progress: {progress:.2f}% [{i+1}/{total_batches}]', end='')

elapsed_time = time.time() - start_time
accuracy = correct / total * 100
print(f'\nAccuracy on the test set: {accuracy:.2f}%, Time: {elapsed_time:.2f}s')